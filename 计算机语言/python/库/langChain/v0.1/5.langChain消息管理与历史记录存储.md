[toc]

## RunnableWithMessageHistory

一个 **高阶封装器**，把一个 `Runnable`（链、模型等）包裹起来，自动处理消息历史。

能在每次调用时，根据一个 session id 获取对应历史，并自动添加用户和 AI 消息。

## BaseChatMessageHistory

这是一个 **抽象类**，定义了管理消息历史的统一接口。

所有的消息历史实现都要继承它，比如使用内存、Redis、DynamoDB等存储方式。

## 存储在内存

### ChatMessageHIstory

`BaseChatMessageHistory` 的一个 **内存中默认实现**。

适用于简单的对话场景或开发阶段，无需持久化。

`使用例子`

```python
import asyncio

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_deepseek import ChatDeepSeek
from pydantic import  SecretStr
from langchain_community.chat_message_histories import  ChatMessageHistory
from langchain_core.chat_history import  BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

llm = ChatDeepSeek(
    model="deepseek-chat",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    api_key = SecretStr("sk-xxxxxxxxxx")
)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You're an assistant who's good at {ability}. Respond in 20 words or fewer"
        ),
        MessagesPlaceholder(variable_name="history"),
        ("human","{input}"),
    ]
)

store={}

runnable = prompt | llm

def get_session_history(session_id:str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# 让runnable具有历史消息功能
with_message_history = RunnableWithMessageHistory(
    runnable,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history",
)

# 调用新的runnable
response = with_message_history.invoke(
    input={"ability":"math","input":"正弦是什么意思"},
    config={"configurable":{"session_id":"abc123"}},
)

print(response)

print("------------------------")

response = with_message_history.invoke(
    input={"ability":"math","input":"什么? 再说一次"},
    config={"configurable":{"session_id":"abc123"}},
)

print(response)

print("------------------------")
#session不同 不再记得
response = with_message_history.invoke(
    input={"ability":"math","input":"什么? 再说一次"},
    config={"configurable":{"session_id":"abc1234"}},
)

print(response)
```

`使用ConfigurableFieldSpec来规范化历史参数`

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_deepseek import ChatDeepSeek
from pydantic import  SecretStr
from langchain_community.chat_message_histories import  ChatMessageHistory
from langchain_core.chat_history import  BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

from langchain_core.runnables.history import  ConfigurableFieldSpec

llm = ChatDeepSeek(
    model="deepseek-chat",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    api_key = SecretStr("sk-3f5705af4ce346689eec074d9e81e11d")
)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You're an assistant who's good at {ability}. Respond in 20 words or fewer"
        ),
        MessagesPlaceholder(variable_name="history"),
        ("human","{input}"),
    ]
)

store={}

runnable = prompt | llm

def get_session_history(user_id:str,conversation_id:str) -> BaseChatMessageHistory:
    if (user_id,conversation_id) not in store:
        store[(user_id,conversation_id)] = ChatMessageHistory()
    return store[(user_id,conversation_id)]

# 让runnable具有历史消息功能
with_message_history = RunnableWithMessageHistory(
    runnable,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history",
    history_factory_config=[
        ConfigurableFieldSpec(
            id="user_id",
            annotation=str,
            name="User ID",
            description="用户唯一标识",
            default="",
            is_shared=True,
        ),
        ConfigurableFieldSpec(
            id="conversation_id",
            annotation=str,
            name="Conversation ID",
            description="对话的唯一标识",
            default="",
            is_shared=True,
        )
    ]
)

# 调用新的runnable
response = with_message_history.invoke(
    input={"ability":"math","input":"正弦是什么意思"},
    config={"configurable":{"user_id":"cjh","conversation_id":"1"}},
)

print(response)


print("----------------")

response = with_message_history.invoke(
    input={"ability":"math","input":"再说一次?"},
    config={"configurable":{"user_id":"cjh","conversation_id":"1"}},
)

print(response)

print("----------------")

response = with_message_history.invoke(
    input={"ability":"math","input":"再说一次?"},
    config={"configurable":{"user_id":"cjh","conversation_id":"2"}},
)

print(response)
```

### RedisChatMessageHistory

集成redis的历史消息

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_deepseek import ChatDeepSeek
from pydantic import  SecretStr
from langchain_community.chat_message_histories import ChatMessageHistory, RedisChatMessageHistory
from langchain_core.chat_history import  BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

from langchain_core.runnables.history import  ConfigurableFieldSpec

llm = ChatDeepSeek(
    model="deepseek-chat",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    api_key = SecretStr("sk-3f5705af4ce346689eec074d9e81e11d")
)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You're an assistant who's good at {ability}. Respond in 20 words or fewer"
        ),
        MessagesPlaceholder(variable_name="history"),
        ("human","{input}"),
    ]
)

REDIS_URL = "redis://127.0.0.1:6379/1"

runnable = prompt | llm

def get_session_history(session_id:str) -> BaseChatMessageHistory:
    return RedisChatMessageHistory(session_id,REDIS_URL)

# 让runnable具有历史消息功能
with_message_history = RunnableWithMessageHistory(
    runnable,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history",
)

# 调用新的runnable
response = with_message_history.invoke(
    input={"ability":"math","input":"正弦是什么意思"},
    config={"configurable":{"session_id":"abc1234"}},
)

print(response)


print("----------------")

response = with_message_history.invoke(
    input={"ability":"math","input":"再说一次?"},
    config={"configurable": {"session_id": "abc1234"}},
)

print(response)

print("----------------")

response = with_message_history.invoke(
    input={"ability":"math","input":"再说一次?"},
    config={"configurable": {"session_id": "abc12345"}},
)

print(response)
```

## 消息裁剪

### RunnablePassthrough

使用RunnablePassthrough可以裁剪和压缩历史消息，避免聊天过长导致历史消息过大，token消耗过多。

#### 裁剪

```python
import asyncio

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_deepseek import ChatDeepSeek
from pydantic import  SecretStr
from langchain_community.chat_message_histories import  ChatMessageHistory
from langchain_core.chat_history import  BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

llm = ChatDeepSeek(
    model="deepseek-chat",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    api_key = SecretStr("sk-xxxxxxxxxx")
)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You're an assistant who's good at {ability}. Respond in 20 words or fewer"
        ),
        MessagesPlaceholder(variable_name="history"),
        ("human","{input}"),
    ]
)

runnable = prompt | llm

temp_chat_history = ChatMessageHistory()
temp_chat_history.add_user_message("正弦是什么?")
temp_chat_history.add_ai_message("对边比斜边")
temp_chat_history.add_user_message("余弦是什么?")
temp_chat_history.add_ai_message("邻边比斜边")
tmp_chat_history.messages
  
# 让runnable具有历史消息功能
with_message_history = RunnableWithMessageHistory(
    runnable,
    lambda session_id: temp_chat_history,		#无视传入的session_id
    input_messages_key="input",
    history_messages_key="history",
)


#限制历史记录为1
def trim_message(chain_input):
  stored_messages = temp_chat_history.message
  if len(stored_messages) <= 1:
    return false
  temp_chat_history.clear()
  for message in stored_messages[-1:]:
    temp_chat_history.add_message(message)
  return True

chain_with_trimming = RunnablePassthrough.assign(messages_trimmed=trim_message) | with_message_history


# 调用新的runnable
print("------------------------")
# 不再记得问过正弦
response = chain_with_trimming.invoke(
    input={"ability":"math","input":"我的第一个问题是什么?"},
    config={"configurable":{"session_id":"abc123"}},
)

```

#### 压缩

```python
import asyncio

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_deepseek import ChatDeepSeek
from pydantic import SecretStr
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

llm = ChatDeepSeek(
    model="deepseek-chat",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    api_key=SecretStr("sk-xxxxxxxxxx")
)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "你是一个乐于助人的助手"
        ),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{input}"),
    ]
)

runnable = prompt | llm

temp_chat_history = ChatMessageHistory()
temp_chat_history.add_user_message("正弦是什么?")
temp_chat_history.add_ai_message("对边比斜边")
temp_chat_history.add_user_message("余弦是什么?")
temp_chat_history.add_ai_message("邻边比斜边")

# 让runnable具有历史消息功能
with_message_history = RunnableWithMessageHistory(
    runnable,
    lambda session_id: temp_chat_history,
    input_messages_key = "input",
    history_messages_key = "chat_history",
)

# 压缩消息
def summarize_messages(chain_input):
    stored_messages = temp_chat_history.messages
    if len(stored_messages) == 0:
        return False
    summarization_prompt = ChatPromptTemplate.from_messages(
        [
            MessagesPlaceholder(variable_name="chat_history"),
            (
                "user",
                "将上述聊天消息浓缩成一条摘要消息，尽可能包含多个具体细节"
            )
        ]
    )
    summarization_chain = summarization_prompt | llm
    summary_message = summarization_chain.invoke({"chat_history": stored_messages})
    temp_chat_history.clear()
    temp_chat_history.add_message(summary_message)
    return True


chain_with_summarization = RunnablePassthrough.assign(message_summarized=summarize_messages) | with_message_history

# 调用新的runnable
print("------------------------")
# 不再记得问过正弦
response = chain_with_summarization.invoke(
    input={"input": "我的第一个问题是什么?"},
    config={"configurable": {"session_id": "abc123"}},
)
print(response)
print(temp_chat_history.messages)


#输出
content='你的第一个问题是关于**直角三角形中的正弦（sin）和余弦（cos）的定义**，具体内容是：  \n\n> **正弦（sin）**定义为**对边与斜边的比值**，而**余弦（cos）**定义为**邻边与斜边的比值**。两者均为三角函数，用于描述角度与边长关系。  \n\n需要我进一步解释或补充相关内容吗？ 😊' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 69, 'total_tokens': 149, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 69}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3d5141a69a_prod0225', 'id': '05d423f9-4157-4709-acef-c57aca7306c3', 'finish_reason': 'stop', 'logprobs': None} id='run-f64932d5-664e-44ad-9902-76a05d27c2d1-0' usage_metadata={'input_tokens': 69, 'output_tokens': 80, 'total_tokens': 149, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}
[AIMessage(content='**摘要消息**：  \n在直角三角形中，**正弦（sin）**定义为**对边与斜边的比值**，而**余弦（cos）**定义为**邻边与斜边的比值**。两者均为三角函数，用于描述角度与边长关系。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 40, 'total_tokens': 94, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 40}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3d5141a69a_prod0225', 'id': '43a1bbd5-8e23-48e6-8a4f-c84f48a2b203', 'finish_reason': 'stop', 'logprobs': None}, id='run-cc9205fb-088d-4398-ae7a-7589b53205a6-0', usage_metadata={'input_tokens': 40, 'output_tokens': 54, 'total_tokens': 94, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}), HumanMessage(content='我的第一个问题是什么?', additional_kwargs={}, response_metadata={}), AIMessage(content='你的第一个问题是关于**直角三角形中的正弦（sin）和余弦（cos）的定义**，具体内容是：  \n\n> **正弦（sin）**定义为**对边与斜边的比值**，而**余弦（cos）**定义为**邻边与斜边的比值**。两者均为三角函数，用于描述角度与边长关系。  \n\n需要我进一步解释或补充相关内容吗？ 😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 69, 'total_tokens': 149, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 69}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3d5141a69a_prod0225', 'id': '05d423f9-4157-4709-acef-c57aca7306c3', 'finish_reason': 'stop', 'logprobs': None}, id='run-f64932d5-664e-44ad-9902-76a05d27c2d1-0', usage_metadata={'input_tokens': 69, 'output_tokens': 80, 'total_tokens': 149, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]

```

